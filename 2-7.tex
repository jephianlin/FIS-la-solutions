\section{Homogeneous Linear Differential Equations with Constant Coeficients}
\begin{enumerate}
\item \begin{enumerate}
\item Yes. It comes from Theorem 2.32.
\item Yes. It comes from Theorem 2.28.
\item No. The equation $y=0$ has the auxiliary polynomial $p(t)=1$. But $y=1$ is not a solution.
\item No. The function $y=e^t+e^{-t}$ is a solution to the linear differential equation $y''-y=0$.
\item Yes. The differential operator is linear.
\item No. The differential equation $y''-2y'+y=0$ has a solution space of dimension two. So $\{e^t\}$ could not be a basis.
\item Yes. Just pick the differential equation $p(D)(y)=0$.
\end{enumerate}
\item \begin{enumerate}
\item No. Let $W$ be a finite-dimensional subspace generated by the function $y=t$. Thus $y$ is a solution to the trivial equation $0y=0$. But the solution space is $C^{\infty }$ but not $W$. Since $y^{(k)}=0$ for $k\geq 2$ and it is impossible that 
\[ay'+by=a+bt=0\]
for nonzero $a$, $W$ cannot be the solution space of a homogeneous linear differential equation with constant coefficients.
\item No. By the previous argument, the solution subspace containing $y=t$ must be $C^{\infty}$.
\item Yes. If $x$ is a solution to the homogeneous linear differential equation with constant coefficients whose is auxiliary polynomial $p(t)$, then we can compute that $p(D)(x')=D(p(D)(x))=0$.
\item Yes. Compute that 
\[p(D)q(D)(x+y)=q(D)p(D)(x)+p(D)q(D)(x)=0.\]
\item No. For example, $e^t$ is a solution for $y'-y=0$ and $e^{-t}$ is a solution for $y'+y=0$, but $1=e^te^{-t}$ is not a solution for $y''-y=0$.
\end{enumerate}
\item Use Theorem 2.34.\begin{enumerate}
\item The basis is $\{e^{-t},te^{-t}\}$.
\item The basis is $\{1,e^{t},e^{-t}\}$.
\item The basis is $\{e^t,te^t,e^{-t},te^{-t}\}$.
\item The basis is $\{e^{-t},te^{-t}\}$.
\item The basis is $\{e^{-t},e^{\alpha t},e^{\overline{\alpha}t}\}$, where $\alpha $ is the complex value $1+2i$.
\end{enumerate}
\item Use Theorem 2.34.\begin{enumerate}
\item The basis is $\{e^{\alpha t},e^{\beta t}\}$, where $\alpha =\frac{1+\sqrt{5}}{2}$ and $\beta=\frac{1-\sqrt{5}}{2}$.
\item The basis is $\{e^t,te^t,t^2e^t\}$.
\item The basis is $\{1,e^{-2t},e^{-4t}\}$.
\end{enumerate}
\item If $f$ and $g$ are elements in $C^{\infty}$, then we know that the $k$-th derivative of $f+g$ exists for all integer $k$ since 
\[(f+g)^{(k)}=f^{(k)}+g^{(k)}.\]
So $f+g$ is also an element in $C^{\infty}$. Similarly, for any scalar $c$, the $k$-th derivative of $cf$ exists for all integer $k$ since $(cf)^{(k)}=cf^{(k)}$. Finally, the function $f=0$ is an element in $C^{\infty}$ naturally.
\item \begin{enumerate}
\item Use the fact 
\[D(f+cg)=D(f)+cD(g)\]
for functions $f,g\in C^{\infty}$ and scalar $c$. This fact is a easy property given in the Calculus course.
\item If $p(t)$ is a polynomial, then the differential operator $p(D)$ is linear by Theorem E.3.
\end{enumerate}
\item Let $W$ and $V$ be the two subspaces generated by the two sets $\{x,y\}$ and $\{\frac{1}{2}(x+y),\frac{1}{2i}(x-y)\}$ separately. We know that $W\supset V$ since $\frac{1}{2}(x+y)$ and $\frac{1}{2i}(x-y)$ are elements in $W$. And it is also true that $W\subset V$ since 
\[x=\frac{1}{2}(x+y)+\frac{i}{2i}(x-y)\]
and 
\[y=\frac{1}{2}(x+y)-\frac{i}{2i}(x-y)\]
are elements in $V$.
\item Compute that $e^{(a\pm ib)t}=e^{at}e^{ibt}=(\cos bt+i\sin bt)e^{at}$. By Theorem 2.34 and the previous exercise we get the result.
\item Since those $U_i$ are pairwise commutative, we may just assume that $i=n$. Hence if $U_n(x)=0$ for some $x\in V$, then 
\[U_1U_2\cdots U_n(x)=U_1U_2\cdots U_{n-1}(0)=0.\]
\item Use induction on the number $n$ of distinct scalar $c_i$'s. When $n=1$, the set $\{e^{c_1t}\}$ is independent since $e^{c_1t}$ is not identically zero. Suppose now the set $\{e^{c_1t},e^{c_2t},\ldots ,e^{c_nt}\}$ is independent for all $n<k $ and for distinct $c_i$'s. Assume that 
\[\sum_{i=1}^k{b_ie^{c_it}}=0.\]
Since any differential operator is linear, we have 
\[0=(D-c_kI)(\sum_{i=1}^k{b_ie^{c_kt}})=\sum_{i=1}^{k-1}{(c_i-c_k)b_ie^{c_it}}.\]
This means that $(c_i-c_k)b_i=0$ and so $b_i=0$ for all $i<k$ by the fact that $c_i$'s are all distinct. Finally $b_k$ is also zero since 
\[b_ke^{c_kt}=0.\]
\item Denote the given set in Theorem 2.34 to be $S$. All the element in the set $S$ is a solution by the proof of the Lemma before Theorem 2.34. Next, we prove that $S$ is linearly independent by induction on the number $k$ of distinct zeroes. For the case $k=1$, it has been proven by the Lemma before Theorem 2.34. Suppose now the set $S$ is linearly independent for the case $k< m$. Assume that 
\[\sum_{i=1}^m{\sum_{j=0}^{n_i-1}{b_{i,j}t^je^{c_it}}}=0\]
for some coefficient $b_{i,j}$. Observe that 
\[(D-c_mI)(t^je^{c_it})=jt^{j-1}e^{c_it}+(c_i-c_m)t^je^{c_it}.\]
Since any differential operator is linear, we have 
\[(D-c_mI)^{n_m}(\sum_{i=1}^m{\sum_{j=0}^{n_i-1}{b_{i,j}t^je^{c_it}}})=0.\]
Since all terms fo $i=m$ are vanished by the differential operator, we may apply the induction hypothesis and know the coefficients for all terms in the left and side is zero. Observer that the coefficient of the term $t^{n_i-1}e^{c_it}$ is $(c_i-c_m)^{n_m}b_{i,n_i-1}$. This means $(c_i-c_m)^{n_m}b_{i,n_i-1}=0$ and so $b_{i,n_i-1}=0$ for all $i<m$. Thus we know that the coefficient of the term $t^{n_i-2}e^{c_it}$ is $(c_i-c_m)^{n_m}b_{i,n_i-2}$. Hence $b_{i,n_i-2}=0$ for all $i<m$. Doing this inductively, we get $b_{i,j}=0$ for all $i<m$. Finally, the equality 
\[\sum_{j=0}^{n_m-1}{b_{m,j}t^je^{c_mt}}=0\]
implies $b_{m,j}=0$ for all $j$ by the Lemma before Theorem 2.34. Thus we complete the proof.
\item The second equality is the definition of range. To prove the first equality, we observe that $R(g(D_V))\subset N(h(D))$ since 
\[h(D)(g(D)(V))=p(D)(V)=\{0\}.\]
Next observe that 
\[N(g(D_V))=N(g(D))\]
since $N(g(D))$ is a subspace in $V$. By Theorem 2.32, the dimension of $N(g(D_V))=N(g(D))$ is the degree of $g$. So the dimension of $R(g(D_V))$ is the degree of $h(t)$ minus the degree of $g(t)$, that is the degree of $h(t)$. So $N(h(D))$ and $R(g(D_V))$ have the same dimension. Hence they are the same.
\item \begin{enumerate}
\item The equation could be rewriten as $p(D)(y)=x$, where $p(t)$ is the auxiliary polynomial of the equation. Since $D$ is surjective by the Lemma 1 after Theorem 2.32, the differential operator $p(D)$ is also surjective. Hence we may find some solution $y_0$ such that $p(D)(y_0)=x$.
\item Use the same notation in the previous question. We already know that $p(D)(z)=x$. If $w$ is also a solution such that $p(D)(w)=x$, then we have 
\[p(D)(w-z)=p(D)(w)-p(D)(z)=x-x=0.\]
So all the solution must be of the form $z+y$ for some $y$ in the solution space $V$ for the homogeneous linear equation.
\end{enumerate}
\item We use induction on the order $n$ of the equation. Let $p(t)$ be the auxiliary polynomial of the equation. If now $p(t)=t-c$ for some coeficient $c$, then the solution is $Ce^{ct}$ for some constant $C$ by Theorem 2.34. So if $Ce^{ct_0}=0$ for some $t_0\in \R$, then we know that $C=0$ and the solution is the zero function. Suppose the statement is true for $n<k$. Now assume the degree of $p(t)$ is $k$. Let $x$ be a solution and $t_0$ is a real number. For an arbitrary scalar $c$, we factor $p(t)=q(t)(t-c)$ for a polynomial $q(t)$ of degree $k-1$ and set $z=q(D)(x)$. We have $(D-cI)(z)=0$ since $x$ is a solution and $z(t_0)=0$ since $x^{(i)}(t_0)=0$ for all $0\leq i\leq n-1$. Again, $z$ must be of the form $Ce^{ct}$. And so $Ce^{ct_0}=0$ implies $C=0$. Thus $z$ is the zero function. Now we have $q(D)(x)=z=0$. By induction hypothesis, we get the conclusion that $x$ is identically zero. This complete the proof.
\item \begin{enumerate}
\item The mapping $\Phi $ is linear since the differential operator $D$ is linear. If $\Phi(x)=0$, then $x$ is the zero function by the previouse exercise. Hence $\Phi$ is injective. And the solution space is an $n$-dimensional space by Theorem 2.32. So The mapping is an isomorphism.
\item This comes from the fact the transformation $\Phi$ defined in the previous question is an isomorphism.
\end{enumerate}
\item \begin{enumerate}
\item Use Theorem 2.34. The auxiliary polynomial is $t^2+\frac{g}{l}$. Hence the basis of the solution space is 
\[\{e^{it\sqrt{\frac{g}{l}}},e^{-it\sqrt{\frac{g}{l}}}\}\]
or 
\[\{\cos t\sqrt{\frac{g}{l}},\sin t\sqrt{\frac{g}{l}}\}\]
by Exercise 2.7.8. So the solution should be of the form 
\[\theta(t)=C_1\cos t\sqrt{\frac{g}{l}}+C_2\sin t\sqrt{\frac{g}{l}} \]
for some constants $C_1$ and $C_2$.
\item Assume that 
\[\theta(t)=C_1\cos t\sqrt{\frac{g}{l}}+C_2\sin t\sqrt{\frac{g}{l}} \]
for some constants $C_1$ and $C_2$ by the previous argument. Consider the two initial conditions
\[\theta(0)=C_1\sqrt{\frac{g}{l}}=\theta_0 \]
and 
\[\theta'(0)=C_2\sqrt{\frac{g}{j}}=0. \]
Thus we get 
\[C_1=\theta_0\sqrt{\frac{l}{g}}\]
and 
\[C_2=0.\]
So we get the unique solution 
\[\theta(t)=\theta_0\sqrt{\frac{l}{g}}\cos t\sqrt{\frac{g}{l}}.\]
\item The period of $\cos t\sqrt{\frac{g}{l}}$ is $2\pi\sqrt{\frac{l}{g}}$. Since the solution is unique by the previous argument, the pendulum also has the same period.
\end{enumerate}
\item The auxiliary polynomial is $t^2+\frac{k}{m}$. So the general solution is 
\[y(t)=C_1\cos t\sqrt{\frac{k}{m}}+C_2\sin t\sqrt{\frac{k}{m}} \]
for some constants $C_1$ and $C_2$ by Exercise 2.7.8.
\item \begin{enumerate}
\item The auxiliary polynomial is $mt^2+rt+k$. The polynomial has two zeroes
\[\alpha=\frac{-r+\sqrt{r^2-4mk}}{2m}\]
and 
\[\beta=\frac{-r-\sqrt{r^2-4mk}}{2m}.\]
So the general solution to the equation is 
\[y(t)=C_1e^{\alpha t}+C_2e^{\beta t}.\]
\item By the previous argument assume the solution is 
\[y(t)=C_1e^{\alpha t}+C_2e^{\beta t}.\]
Consider the two initial conditions 
\[y(0)=C_1+C_2=0\]
and 
\[y'(0)=\alpha C_1+\beta C_2=v_0.\]
Solve that 
\[C_1=(\alpha-\beta)^{-1}v_0\]
and 
\[C_2=(\beta-\alpha)^{-1}v_0.\]
\item The limit tends to zero since the real parts of $\alpha$ and $\beta$ is both $-\frac{r}{2m}$, a negative value, by assuming the $r^2-4mk\leq 0$. Even if $r^2-4mk>0$, we still know that $\alpha$ and $\beta$ are negative real number.
\end{enumerate}
\item Since $\mathcal{F}(\R,\R)$ is a subset of $\mathcal{F}(\C,\C)$, so if the solution which is useful in describing physical motion, then it will still be a real-valued function.
\item \begin{enumerate}
\item Assume the differential equation has monic auxiliary polynomial $p(t)$ of degree $n$. Thus we know that $p(D)(x)=0$ if $x$ is a solution. This means that $x^{(k)}$ exists for all integer $k\leq n$. We may write $p(t)$ as $t^n+q(t)$, where $q(t)=p(t)-t^n$ is a polynomial of degree less than $n$. Thus we have 
\[x^{(n)}=-q(D)(x)\]
is differentiable since $x^{(n)}$ is a linear combination of lower order terms $x^{(k)}$ with $k\leq n-1$. Doing this inductively, we know actualy $x$ is an element in $C^{\infty}$.
\item For complex number $c$ and $d$, we may write $c=c_1+ic_2$ and $d=d_1+id_2$ for some real numbers $c_1$, $c_2$, $d_1$, and $d_2$. Thus we have 
\[e^{c+d}=e^{(c_1+d_1)+i(c_2+d_2)}=e^{c_1}e^{d_1}(\cos (c_2+d_2)+i\sin (c_2+d_2))\]
and 
\[e^ce^d=e^c_1e^d_1(\cos c_2+i\sin c_2)(\cos d_2 +i\sin d_2)\]
\[=e^c_1e^d_1[(\cos c_2\cos d_2-\sin c_2\sin d_2)+i(\sin c_2\cos d_2 +\cos c_2\sin d_2)]\]
\[=e^{c_1}e^{d_1}(\cos (c_2+d_2)+i\sin (c_2+d_2)).\]
This means $e^{c+d}=e^ce^d$ even if $c$ and $d$ are complex number.\footnote{The textbook has a typo that $e^{c+d}=c^ce^d$.} For the second equality, we have 
\[1=e^{0}=e^{c-c}=e^{c}e^{-c}.\]
So we get 
\[e^{-c}=\frac{1}{e^c}.\]
\item Let $V$ be the set of all solution to the homogeneous linear differential equation with constant coefficient with auxiliary polynomial $p(t)$. Since each solution is an element in $C^{\infty}$, we know that $V\supset N(p(D))$, where $N(p(D))$ is the null space of $p(D)$, since $p(D)(x)=0$ means that $x$ is a solution. Conversely, if $x$ is a solution, then we have $p(D)(x)=0$ and so $x\in N(p(D))$.
\item Let $c=c_1+ic_2$ for some real numbers $c_1$ and $c_2$. Directly compute that 
\[(e^{ct})'=(e^{c_1t+ic_2t})'=(e^{c_1t}(\cos c_2t+i\sin c_2t))'\]
\[c_1e^{c_1t}(\cos c_2t+i\sin c_2t))+ic_2e^{c_1t}(\cos c_2t+i\sin c_2t)\]
\[(c_1+ic_2)e^{c_1t}(\cos c_2t+i\sin c_2t)=ce^{ct}.\]
\item Assume that $x=x_1+ix_2$ and $y=y_1+iy_2$ for some $x_1$, $x_2$, $y_1$, and $y_2$ in $\mathcal{F}(\R,\R)$. Compute that 
\[(xy)'=(x_1y_1-x_2y_2)'+i(x_1y_2+x_2y_1)'\]
\[=(x_1'y_1+x_1y_1'-x_2'y_2-x_2y_2')+i(x_1'y_2+x_1y_2'+x_2'y_1+x_2y_1')\]
\[=(x_1'+ix_2')(y_1+iy_2)+(x_1+ix_2)(y_1'+iy_2')=x'y+xy'.\]
\item Assume that $x=x_1+ix_2$ for some $x_1$ and $x_2$ in $\mathcal{F}(\R,\R)$. If 
\[x'=x_1'+ix_2'=0,\]
then $x_1'=0$ and $x_2'=0$ since $x_1'$ and $x_2'$ are real-valued functions. Hence $x_1$ and $x_2$ are constant in $\R$. Hence $x$ is a constant in $\C$.
\end{enumerate}
\end{enumerate}